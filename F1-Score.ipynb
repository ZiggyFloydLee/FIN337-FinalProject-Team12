{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75b162b-39e0-4173-a790-a4d113748d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenm\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f780f1e-4389-4db1-96d2-baaa9ec04d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenm\\AppData\\Local\\Temp\\ipykernel_12228\\3959192827.py:9: DtypeWarning: Columns (30,34,953,954,955,956,963,964,965,966,967) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score, recall_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'inputs/masterMerge.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Get the total number of instances in the dataset\n",
    "total_instances = len(df)\n",
    "\n",
    "# Define your features and the target variable\n",
    "features = ['adrr', 'curuscn', 'scf', 'src', 'acominc',\n",
    "                 'acox', 'at', 'am', 'ao', 'aoloch', 'aox', 'ap', 'at', 'caps', 'capx', 'cb',\n",
    "                 'ch', 'che', 'clg', 'cogs', 'csho', 'cshrt', 'cstk', 'dd', 'dlc',\n",
    "                 'dn', 'do', 'dt', 'ebit', 'ebitda', 'epspi', 'fca', 'ffo', 'gdwl',\n",
    "                 'gp', 'ib', 'intan', 'invt', 'lt', 'lct', 'ni', 'niadj', 'np', 'pi', 'ppegt',\n",
    "                 'pnrsho', 'ppent', 're', 'revt', 'sale', 'seq', 'tdc', 'teq', 'tstk', 'txt',\n",
    "                 'wcap', 'naicsh', 'mkvalt', 'acchg', 'accrt', 'amc', 'ano', 'arce', 'cshi',\n",
    "                 'depc', 'derhedgl']\n",
    "target = 'IS_SPAC'\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target}' not found in the dataset.\")\n",
    "\n",
    "# Fill NaN values in 'IS_SPAC' with 0 to indicate non-SPAC companies\n",
    "df[target] = df[target].fillna(0)\n",
    "\n",
    "# Convert the target column to an integer type\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "df_clean = pd.get_dummies(df)\n",
    "\n",
    "# Separate the features (X) and the target (y)\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Handle missing values in features by imputing with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y, y_pred)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Analyze feature importance (coefficients)\n",
    "importance = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_[0]})\n",
    "importance.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\nFeature Importance (Coefficients):\")\n",
    "print(importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a83241-525e-401e-a00f-d088dc704396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'inputs/master_filtered_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Get the total number of instances in the dataset\n",
    "total_instances = len(df)\n",
    "\n",
    "# Define your features and the target variable\n",
    "features = ['adrr', 'curuscn', 'scf', 'src', 'acominc',\n",
    "                 'acox', 'at', 'am', 'ao', 'aoloch', 'aox', 'ap', 'at', 'caps', 'capx', 'cb',\n",
    "                 'ch', 'che', 'clg', 'cogs', 'csho', 'cshrt', 'cstk', 'dd', 'dlc',\n",
    "                 'dn', 'do', 'dt', 'ebit', 'ebitda', 'epspi', 'fca', 'ffo', 'gdwl',\n",
    "                 'gp', 'ib', 'intan', 'invt', 'lt', 'lct', 'ni', 'niadj', 'np', 'pi', 'ppegt',\n",
    "                 'pnrsho', 'ppent', 're', 'revt', 'sale', 'seq', 'tdc', 'teq', 'tstk', 'txt',\n",
    "                 'wcap', 'naicsh', 'mkvalt', 'acchg', 'accrt', 'amc', 'ano', 'arce', 'cshi',\n",
    "                 'depc', 'derhedgl']\n",
    "target = 'IS_SPAC'\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target}' not found in the dataset.\")\n",
    "\n",
    "# Fill NaN values in 'IS_SPAC' with 0 to indicate non-SPAC companies\n",
    "df[target] = df[target].fillna(0)\n",
    "\n",
    "# Convert the target column to an integer type\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "df_clean = pd.get_dummies(df)\n",
    "\n",
    "# Separate the features (X) and the target (y)\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Handle missing values in features by imputing with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using probability estimates\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Define a range of thresholds\n",
    "thresholds = np.linspace(0.15, 0.25, 10)\n",
    "\n",
    "# Initialize variables to store the best F1 score and corresponding threshold\n",
    "best_f1_score = 0\n",
    "best_threshold = 0\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "for threshold in thresholds:\n",
    "    y_pred_adjusted = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_adjusted)\n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Use the best threshold to make predictions\n",
    "y_pred_best_threshold = (y_pred_proba[:, 1] >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate the model using a confusion matrix and metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best_threshold)\n",
    "precision = precision_score(y_test, y_pred_best_threshold)\n",
    "accuracy = accuracy_score(y_test, y_pred_best_threshold)\n",
    "recall = recall_score(y_test, y_pred_best_threshold)\n",
    "\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nMetrics:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", best_f1_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e23bf2-6cc6-426c-86af-e7c0d67a6497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('inputs/masterMerge.csv', low_memory=False)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f07d1a-3dc1-4c9c-b910-8c7bdbff04aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description_path = 'varDescriptionCHATGPT.txt'\n",
    "with open(description_path, 'r') as file:\n",
    "    variable_descriptions = file.read()\n",
    "    \n",
    "variable_descriptions[:] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
