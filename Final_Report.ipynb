{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report on Predictive Modeling for Optimal Capital Market Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final report notebook for Team 12 in FIN 377. In this notebook we will explore our processes, modeling, as well as our conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start: These are all the packages we used throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data download and cleaning packages.\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "# We tried to fuzzymatch firms to their names, but ran into trouble and manually matched the CUSIPS\n",
    "# !pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, r2_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Other Packages\n",
    "from tqdm import tqdm\n",
    "# We did not end up using wrds in our final process, but we thought it was a cool database and included it.\n",
    "# !pip install wrds\n",
    "# import wrds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On to the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a lot of data in this project. It was very hard to clean, but we got there in the end.\n",
    "\n",
    "The goal was to end up with a merged dataset of 3 inputs:\n",
    "- Jay Ritter's SPAC data\n",
    "    - This data contains all SPAC mergers from 2016-2021.\n",
    "- Jay Ritter's IPO data\n",
    "    - This data contains all IPOs since 1975\n",
    "- CCM data\n",
    "    - This data contains 950 columns of observations on firms from 2000-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried several methods to refine our final dataset:\n",
    "\n",
    "1. We started by merging the different CUSIPs provided in each dataset.\n",
    "- The problem with this method was that we could merge all the data together, only to find that there were 0 SPAC observations Â·in the resulting dataset.\n",
    "- We learned this is because the CUSIPs overlapped a bit between SPAC data and both IPO and CCM data, but none of the SPACs had CUSIPs that matched both datasets.\n",
    "\n",
    "2. FuzzyWuzzy -- We tried running a fuzzy match on the company names given in each dataset.\n",
    "- This worked somewhat well but was prone to inaccurate readings.\n",
    "- There was a company called 'Acquisition,' which the fuzzy match thought looked similar to any SPAC named 'Bob Joe Acquisition Corp.'\n",
    "- When we deleted this company, we ran a fuzzy match that took 3 hours!\n",
    "- It worked for about 60% of the data, but when combined with a confidence level of 90%, the fuzzy match ended up with only around 20% of SPACs.\n",
    "\n",
    "3. Manually adding merge keys\n",
    "- We realized that the most accurate way to gather all the data would be to merge on CUSIP, as all of the datasets have them, - and although some are different, we could manually go through the SPAC dataset to match them to the IPO and CCM datasets.\n",
    "- This worked! We ended up creating CCM_Cusip.csv, which has CUSIP merge keys for both IPO data and CCM data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Below is the final merge we came up with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/56zwk80s1dl703mqbltv_bq00000gn/T/ipykernel_68556/616900804.py:4: DtypeWarning: Columns (29,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ccm_df = pd.read_csv('inputs/all_ccm_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Downloading data into DFs\n",
    "ipo_age_df = pd.read_csv('inputs/IPO-age(9).csv')\n",
    "cleaned_spacs = pd.read_csv('inputs/CCM_Cusip.csv')\n",
    "ccm_df = pd.read_csv('inputs/all_ccm_data.csv')\n",
    "\n",
    "# Narrowing the horizons to be more memory-friendly\n",
    "ipo_age_df = ipo_age_df[ipo_age_df['offer date'] > 20000000]\n",
    "ipo_age_df = ipo_age_df[ipo_age_df['offer date'] < 20190000]\n",
    "ipo_age_df = ipo_age_df.iloc[:, :-3]\n",
    "\n",
    "# Merging the SPAC and IPO data\n",
    "ziggymerge = pd.merge(ipo_age_df, cleaned_spacs, how='left', left_on='CUSIP', right_on='IPO_age_Cusip')\n",
    "\n",
    "# Merging the previous merge with CCM Data\n",
    "ziggymerge2 = pd.merge(left= ccm_df, right= ziggymerge, how='left', left_on='cusip', right_on='CCM_Cusip')\n",
    "ziggymerge2.to_csv('inputs/masterMerge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then filtered this data based on what was streamlit-friendly and what numeric values we thought would be best to model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next up: Modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our final project proposal, we explored KNN and Logistic Regression models. We tested these two models and found that Logistic Regression had the best recall score for the dataset.\n",
    "\n",
    "*Some caveats:*\n",
    "\n",
    "1. Although Logistic Regression was the highest-scoring model, we achieved our highest score by using 66 variables! This is far too many for a user to input on our dashboard.\n",
    "\n",
    "**How did we solve this?**\n",
    "\n",
    "To address this, we conducted feature importance testing. We found that not many of the features had high correlations in determining whether a given IPO was a SPAC or not. However, we chose the top 5 variables to include on our dashboard. These variables were:\n",
    "\n",
    "- Industry Code\n",
    "- Cash Increase\n",
    "- Market Value\n",
    "- EPS (Earnings Per Share)\n",
    "- Cash and Short Term Investments\n",
    "\n",
    "2. We thought that, although it was less accurate, the KNN model was better for the interactive aspect of our dashboard. We believe this because users can see where their inputs lie within our model, and receive a 'Top 5 Most Comparable Companies' output.\n",
    "\n",
    "**An issue with the KNN model:**\n",
    "\n",
    "Since the dataset ranges from 2000 to 2018, there are many companies with multiple observations across the dataset. There is one company, WARNER CHILCOTT PLC, with 11 observations. Given that the SPAC dataset only covers from 2016 to 2021, and we narrowed this down to 2016 to 2018, the most observations a SPAC can have in this dataset is 3. This means that for a user input that the model guesses is most like a SPAC, there may be up to 3 of the top 5 comparable companies that are actually the same company in different years. We observed this with a couple of our tests of the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With this in mind, here are our models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.18333333333333332\n",
      "Confusion Matrix:\n",
      "[[8277   31]\n",
      " [   6   23]]\n",
      "\n",
      "Metrics:\n",
      "Precision: 0.42592592592592593\n",
      "F1 Score: 0.5542168674698795\n",
      "Accuracy: 0.9955619527407941\n",
      "Recall: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'inputs/master_filtered_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Get the total number of instances in the dataset\n",
    "total_instances = len(df)\n",
    "\n",
    "# Define features and the target variable\n",
    "features = ['adrr', 'curuscn', 'scf', 'src', 'acominc',\n",
    "                 'acox', 'at', 'am', 'ao', 'aoloch', 'aox', 'ap', 'at', 'caps', 'capx', 'cb',\n",
    "                 'ch', 'che', 'clg', 'cogs', 'csho', 'cshrt', 'cstk', 'dd', 'dlc',\n",
    "                 'dn', 'do', 'dt', 'ebit', 'ebitda', 'epspi', 'fca', 'ffo', 'gdwl',\n",
    "                 'gp', 'ib', 'intan', 'invt', 'lt', 'lct', 'ni', 'niadj', 'np', 'pi', 'ppegt',\n",
    "                 'pnrsho', 'ppent', 're', 'revt', 'sale', 'seq', 'tdc', 'teq', 'tstk', 'txt',\n",
    "                 'wcap', 'naicsh', 'mkvalt', 'acchg', 'accrt', 'amc', 'ano', 'arce', 'cshi',\n",
    "                 'depc', 'derhedgl']\n",
    "target = 'IS_SPAC'\n",
    "\n",
    "# Make sure the target column exists\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target}' not found in the dataset.\")\n",
    "\n",
    "# Fill NaN values in 'IS_SPAC' with 0 to indicate non-SPAC companies\n",
    "df[target] = df[target].fillna(0)\n",
    "\n",
    "# Convert the target column to an integer type\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# Convert categorical variables to numeric variables using one-hot encoding\n",
    "df_clean = pd.get_dummies(df)\n",
    "\n",
    "# Separate the features (X) and the target (y)\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Handle missing values in features by imputing with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using probability estimates\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Define a range of thresholds\n",
    "thresholds = np.linspace(0.15, 0.25, 10)\n",
    "\n",
    "# Initialize variables to store the best F1 score and corresponding threshold\n",
    "best_f1_score = 0\n",
    "best_threshold = 0\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "for threshold in thresholds:\n",
    "    y_pred_adjusted = (y_pred_proba[:, 1] >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_adjusted)\n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Use the best threshold to make predictions\n",
    "y_pred_best_threshold = (y_pred_proba[:, 1] >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate the model using a confusion matrix and metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best_threshold)\n",
    "precision = precision_score(y_test, y_pred_best_threshold)\n",
    "accuracy = accuracy_score(y_test, y_pred_best_threshold)\n",
    "recall = recall_score(y_test, y_pred_best_threshold)\n",
    "\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nMetrics:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", best_f1_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we also did threshold testing which can be seen in the image below:\n",
    "\n",
    "![Threshold Tesing](outputs/F1ScoresVsThresholds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 0.72\n",
      "Recall: 0.54\n",
      "F1 Score: 0.62\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      5534\n",
      "         1.0       0.72      0.54      0.62        24\n",
      "\n",
      "    accuracy                           1.00      5558\n",
      "   macro avg       0.86      0.77      0.81      5558\n",
      "weighted avg       1.00      1.00      1.00      5558\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5529    5]\n",
      " [  11   13]]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "merged_df = pd.read_csv('inputs/master_filtered_data.csv', low_memory=False)\n",
    "\n",
    "# Define features and target column names\n",
    "features = ['adrr', 'curuscn', 'scf', 'src', 'acominc', 'acox', 'at',\n",
    "            'am', 'ao', 'aoloch', 'aox', 'ap', 'at.1', 'caps', 'capx', 'cb',\n",
    "            'ch', 'che', 'clg', 'cogs', 'csho', 'cshrt', 'cstk', 'dd', 'dlc',\n",
    "            'dn', 'do', 'dt', 'ebit', 'ebitda', 'epspi', 'fca', 'ffo',\n",
    "            'gdwl', 'gp', 'ib', 'intan', 'invt', 'lt', 'lct', 'ni',\n",
    "            'niadj', 'np', 'pi', 'ppegt', 'pnrsho', 'ppent', 're', 'revt',\n",
    "            'sale', 'seq', 'tdc', 'teq', 'tstk', 'txt', 'wcap', 'naicsh',\n",
    "            'mkvalt', 'acchg', 'accrt', 'amc', 'ano', 'arce', 'cshi',\n",
    "            'depc', 'derhedgl']\n",
    "target = 'IS_SPAC'\n",
    "\n",
    "# Check which features exist in the dataset\n",
    "valid_features = [col for col in features if col in merged_df.columns]\n",
    "\n",
    "# Create a DataFrame with the required features and target\n",
    "data = merged_df[valid_features + [target]]\n",
    "\n",
    "# Handle missing values with mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(data[valid_features])\n",
    "y = data[target]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate and train KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, The Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The dashboard has been mentioned previously in our report, but there is more to explain. We built our dashboard in the \"app.py\" file, and used Streamlit to run it.\n",
    "\n",
    "The dashboard provides a brief explanation of our project, our purpose, and then features two tabs for our models, along with a sidebar for user interaction with these models.\n",
    "\n",
    "The KNN Model tab is made to be the more interactive of the two, where a user may input a company--real or fake--and our dashboard will indicate whether our model thinks the company is most likely a SPAC or an IPO. The dashboard also outputs the five most comparable company tickers.\n",
    "\n",
    "The Logistic Regression Model is intended for useres who want to explore our model and data more closely. It displays the model performance through two different feature varaibles that the user selects on the sidebar drop down options. \n",
    "\n",
    "#### Screenshots of the dashboard showing the functionality of the Logistic Regression Model and the KNN Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sidebar](outputs/SideBar.png)\n",
    "![KNN Model](outputs/KNNPLOT.png)\n",
    "![Logistic Regression Model](outputs/LOGREGPLOT.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
