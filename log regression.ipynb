{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9cda94-7a70-477a-a0b6-1781c6fd8c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[8307    1]\n",
      " [  29    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         IPO       1.00      1.00      1.00      8308\n",
      "        SPAC       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           1.00      8337\n",
      "   macro avg       0.50      0.50      0.50      8337\n",
      "weighted avg       0.99      1.00      0.99      8337\n",
      "\n",
      "\n",
      "Feature Importance (Coefficients):\n",
      "    Feature  Coefficient\n",
      "0  optprcgr     0.069942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/56zwk80s1dl703mqbltv_bq00000gn/T/ipykernel_45889/1948186983.py:5: DtypeWarning: Columns (30,34,953,954,955,956,963,964,965,966,967) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'inputs/masterMerge.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Define your features and the target variable\n",
    "features = ['optprcgr']\n",
    "target = 'IS_SPAC'\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target}' not found in the dataset.\")\n",
    "\n",
    "# Fill NaN values in 'IS_SPAC' with 0 to indicate non-SPAC companies\n",
    "df[target] = df[target].fillna(0)\n",
    "\n",
    "# Convert the target column to an integer type\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# Separate the features (X) and the target (y)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Handle missing values in features by imputing with the mean of each column\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features to ensure all variables are on the same scale (optional but recommended)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using a confusion matrix and classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=['IPO', 'SPAC'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Analyze feature importance (coefficients)\n",
    "importance = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_[0]})\n",
    "importance.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\nFeature Importance (Coefficients):\")\n",
    "print(importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03dec441-4ab6-40a5-816d-93ca088b0b45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/56zwk80s1dl703mqbltv_bq00000gn/T/ipykernel_45889/2185454148.py:6: DtypeWarning: Columns (30,34,953,954,955,956,963,964,965,966,967) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['tic', 'apdedate', 'fdate', 'pdate', 'cusip', 'datadate'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Separate the features (X) and the target (y)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m X \u001b[38;5;241m=\u001b[39m df_clean[features]\n\u001b[1;32m     40\u001b[0m y \u001b[38;5;241m=\u001b[39m df_clean[target]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Handle missing values in features by imputing with the mean of each column\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['tic', 'apdedate', 'fdate', 'pdate', 'cusip', 'datadate'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'inputs/masterMerge.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Get the total number of instances in the dataset\n",
    "total_instances = len(df)\n",
    "\n",
    "# Define your features and the target variable\n",
    "features = ['adrr', 'curuscn', 'scf', 'src', 'apdedate', 'fdate', 'pdate', 'acominc',\n",
    "                 'acox', 'at', 'am', 'ao', 'aoloch', 'aox', 'ap', 'at', 'caps', 'capx', 'cb',\n",
    "                 'ch', 'che', 'clg', 'cogs', 'csho', 'cusip', 'cshrt', 'cstk', 'dd', 'dlc',\n",
    "                 'dn', 'do', 'datadate', 'dt', 'ebit', 'ebitda', 'epspi', 'fca', 'ffo', 'gdwl',\n",
    "                 'gp', 'ib', 'intan', 'invt', 'lt', 'lct', 'ni', 'niadj', 'np', 'pi', 'ppegt',\n",
    "                 'pnrsho', 'ppent', 're', 'revt', 'sale', 'seq', 'tdc', 'teq', 'tstk', 'txt',\n",
    "                 'wcap', 'naicsh', 'mkvalt', 'acchg', 'accrt', 'amc', 'ano', 'arce', 'cshi',\n",
    "                 'depc', 'derhedgl']\n",
    "target = 'IS_SPAC'\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target}' not found in the dataset.\")\n",
    "\n",
    "# Fill NaN values in 'IS_SPAC' with 0 to indicate non-SPAC companies\n",
    "df[target] = df[target].fillna(0)\n",
    "\n",
    "# Convert the target column to an integer type\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "df_clean = pd.get_dummies(df)\n",
    "\n",
    "# Separate the features (X) and the target (y)\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Handle missing values in features by imputing with the mean of each column\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the model using a confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a271336-6c7f-4768-9ddd-5a4d0e6ca75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
