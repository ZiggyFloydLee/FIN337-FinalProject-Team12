{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ziggy\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "c:\\Users\\ziggy\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# !pip install wrds\n",
    "import wrds\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# !pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_data = pd.read_csv('inputs/IPO-age(9).csv')\n",
    "spac_data = pd.read_csv('inputs/SPACs2016-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CUSIP in IPO dataset: False\n",
      "Unique CUSIP in SPAC dataset: False\n"
     ]
    }
   ],
   "source": [
    "ipo_unique_cusips = ipo_data['CUSIP'].is_unique\n",
    "spac_unique_cusips = spac_data['CUSIP'].is_unique\n",
    "\n",
    "\n",
    "print(\"Unique CUSIP in IPO dataset:\", ipo_unique_cusips)\n",
    "print(\"Unique CUSIP in SPAC dataset:\", spac_unique_cusips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_data_clean = ipo_data.drop_duplicates(subset='CUSIP', keep='last')\n",
    "spac_data_clean = spac_data.drop_duplicates(subset='CUSIP', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_clean_data = pd.merge(ipo_data_clean, spac_data_clean, on=['CUSIP'], how='left', suffixes=('_IPO', '_SPAC'))\n",
    "merged_clean_data['IS_SPAC'] = merged_clean_data['SPAC IPO '].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACs Identified:\n",
      "       offer date                        IPO name ticker      CUSIP Rollup VC  \\\n",
      "12695    20160224     Silver Run Acquisition Corp  SRAQU  82811P200      0  0   \n",
      "12696    20160303         Jensyn Acquisition Corp  JSYNU  47632B201      0  0   \n",
      "12724    20160526       Landcadia Holdings II Inc  LCAHU  51476W206      0  0   \n",
      "12736    20160707          M III Acquisition Corp  MIIIU  55378T203      0  0   \n",
      "12758    20160916  Saban Capital Acquisition Corp  SCACU  78516C205      0  0   \n",
      "\n",
      "      Dual Internet Post-issue shares CRSP perm  Founding  Unnamed: 11  \\\n",
      "12695    1        0          45000000     16021       -99          NaN   \n",
      "12696    1        0           5213400     16012      2014          NaN   \n",
      "12724    1        0          30000000     16173      2008          NaN   \n",
      "12736    1        0                -9     16261       -99          NaN   \n",
      "12758    1        0          28500000     16470      2016          NaN   \n",
      "\n",
      "      Unnamed: 12 Unnamed: 13                        SPAC IPO  Date of IPO  \\\n",
      "12695         NaN         NaN     Silver Run Acquisition Corp.   2/29/2016   \n",
      "12696         NaN         NaN         Jensyn Acquisition Corp.    3/7/2016   \n",
      "12724         NaN         NaN         Landcadia Holdings, Inc.    6/1/2016   \n",
      "12736         NaN         NaN          M III Acquisition Corp.    7/7/2016   \n",
      "12758         NaN         NaN  Saban Capital Acquisition Corp.   9/21/2016   \n",
      "\n",
      "       IS_SPAC  \n",
      "12695     True  \n",
      "12696     True  \n",
      "12724     True  \n",
      "12736     True  \n",
      "12758     True  \n",
      "\n",
      "IPOs Not SPACs:\n",
      "   offer date             IPO name ticker     CUSIP Rollup VC Dual Internet  \\\n",
      "0    19750130              ROYSTER    NaN  78088610      .  0    0        0   \n",
      "1    19750609                VARCO    VRC  92212610      .  0    0        0   \n",
      "2    19750610         COORS ADOLPH    TAP  21701610      .  0    1        0   \n",
      "3    19750715  KEYSTONE FOODS CORP    NaN  49348410      .  0    0        0   \n",
      "4    19750826          C. F. BRAUN    NaN  10564710      .  0    0        0   \n",
      "\n",
      "  Post-issue shares CRSP perm  Founding  Unnamed: 11  \\\n",
      "0                 .     67898      1901          NaN   \n",
      "1                 .     63044      1908          NaN   \n",
      "2          35418915     59248      1901          NaN   \n",
      "3                 .     61989      1965          NaN   \n",
      "4                 .     58579      1909          NaN   \n",
      "\n",
      "                                         Unnamed: 12 Unnamed: 13 SPAC IPO   \\\n",
      "0          N=15,447 U.S. IPOs from Jan 1975-Dec 2022         NaN       NaN   \n",
      "1                                                NaN         NaN       NaN   \n",
      "2  Rollup is a 0-1 dummy variable for whether the...         NaN       NaN   \n",
      "3  VC is a dummy with 1 for VC and 2 for a subset...         NaN       NaN   \n",
      "4  Dual is a dummy for multiple share class IPOs ...         NaN       NaN   \n",
      "\n",
      "  Date of IPO  IS_SPAC  \n",
      "0         NaN    False  \n",
      "1         NaN    False  \n",
      "2         NaN    False  \n",
      "3         NaN    False  \n",
      "4         NaN    False  \n"
     ]
    }
   ],
   "source": [
    "spacs_only = merged_clean_data[merged_clean_data['IS_SPAC']]\n",
    "ipos_not_spacs = merged_clean_data[~merged_clean_data['IS_SPAC']]\n",
    "\n",
    "# Display some entries from each dataset\n",
    "print(\"SPACs Identified:\")\n",
    "print(spacs_only.head())\n",
    "\n",
    "print(\"\\nIPOs Not SPACs:\")\n",
    "print(ipos_not_spacs.head())\n",
    "\n",
    "spacs_only.to_csv('inputs/spacs_identified.csv', index=False)\n",
    "ipos_not_spacs.to_csv('inputs/ipos_not_spacs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacs_identified = pd.read_csv('inputs/spacs_identified.csv')\n",
    "ipos_identified = pd.read_csv('inputs/ipos_not_spacs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ipo_spacs = pd.concat([spacs_identified, ipos_not_spacs])\n",
    "combined_ipo_spacs = combined_ipo_spacs.drop_duplicates(subset='CUSIP')\n",
    "combined_ipo_spacs.to_csv('inputs/combined_ipo_spacs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = combined_ipo_spacs[['IPO name', 'ticker', 'CUSIP', 'Date of IPO', 'IS_SPAC']]\n",
    "selected_columns.to_csv('inputs/filtered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_youngfirms = \"inputs/ccm_youngfirms_2000_2018.dta/ccm_youngfirms_2000_2018.dta\"\n",
    "\n",
    "if not os.path.exists(ccm_youngfirms):\n",
    "    zip_path = \"inputs/ccm_youngfirms_2000_2018.zip\"\n",
    "\n",
    "    with zipfile.ZipFile(zip_path,'r') as zip_ref:\n",
    "        zip_ref.extractall(\"inputs/ccm_youngfirms_2000_2018.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_data = pd.read_stata(ccm_youngfirms)\n",
    "ccm_data.to_csv('inputs/all_ccm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_vars = ['tic','adrr', 'curuscn', 'scf', 'src', 'apdedate', 'fdate', 'pdate', 'acominc',\n",
    "                 'acox', 'at', 'am', 'ao', 'aoloch', 'aox', 'ap', 'at', 'caps', 'capx', 'cb',\n",
    "                 'ch', 'che', 'clg', 'cogs', 'csho', 'cusip', 'cshrt', 'cstk', 'dd', 'dlc',\n",
    "                 'dn', 'do', 'datadate', 'dt', 'ebit', 'ebitda', 'epspi', 'fca', 'ffo', 'gdwl',\n",
    "                 'gp', 'ib', 'intan', 'invt', 'lt', 'lct', 'ni', 'niadj', 'np', 'pi', 'ppegt',\n",
    "                 'pnrsho', 'ppent', 're', 'revt', 'sale', 'seq', 'tdc', 'teq', 'tstk', 'txt',\n",
    "                 'wcap', 'naicsh', 'mkvalt', 'acchg', 'accrt', 'amc', 'ano', 'arce', 'cshi',\n",
    "                 'depc', 'derhedgl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_data_filtered =ccm_data[relevant_vars]\n",
    "ccm_data_filtered.to_csv('inputs/ccm_data_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conm</th>\n",
       "      <th>tic</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>Date of IPO</th>\n",
       "      <th>IS_SPAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Silver Run Acquisition Corp</td>\n",
       "      <td>SRAQU</td>\n",
       "      <td>82811P200</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jensyn Acquisition Corp</td>\n",
       "      <td>JSYNU</td>\n",
       "      <td>47632B201</td>\n",
       "      <td>3/7/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Landcadia Holdings II Inc</td>\n",
       "      <td>LCAHU</td>\n",
       "      <td>51476W206</td>\n",
       "      <td>6/1/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M III Acquisition Corp</td>\n",
       "      <td>MIIIU</td>\n",
       "      <td>55378T203</td>\n",
       "      <td>7/7/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Saban Capital Acquisition Corp</td>\n",
       "      <td>SCACU</td>\n",
       "      <td>78516C205</td>\n",
       "      <td>9/21/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>15297</td>\n",
       "      <td>Aimei Health Technology Co.</td>\n",
       "      <td>AFJKU</td>\n",
       "      <td>G01341117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15298</th>\n",
       "      <td>15298</td>\n",
       "      <td>INNO HOLDINGS INC.</td>\n",
       "      <td>INHD</td>\n",
       "      <td>4576JP109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299</th>\n",
       "      <td>15299</td>\n",
       "      <td>ZKH GROUP LTD</td>\n",
       "      <td>ZKH</td>\n",
       "      <td>98877R104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15300</th>\n",
       "      <td>15300</td>\n",
       "      <td>Linkage Global Inc</td>\n",
       "      <td>LGCB</td>\n",
       "      <td>G5500B102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15301</th>\n",
       "      <td>15301</td>\n",
       "      <td>Iron Horse Acquisition</td>\n",
       "      <td>IROHU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15302 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                            conm    tic      CUSIP  \\\n",
       "0               0     Silver Run Acquisition Corp  SRAQU  82811P200   \n",
       "1               1         Jensyn Acquisition Corp  JSYNU  47632B201   \n",
       "2               2       Landcadia Holdings II Inc  LCAHU  51476W206   \n",
       "3               3          M III Acquisition Corp  MIIIU  55378T203   \n",
       "4               4  Saban Capital Acquisition Corp  SCACU  78516C205   \n",
       "...           ...                             ...    ...        ...   \n",
       "15297       15297     Aimei Health Technology Co.  AFJKU  G01341117   \n",
       "15298       15298              INNO HOLDINGS INC.   INHD  4576JP109   \n",
       "15299       15299                   ZKH GROUP LTD    ZKH  98877R104   \n",
       "15300       15300              Linkage Global Inc   LGCB  G5500B102   \n",
       "15301       15301          Iron Horse Acquisition  IROHU        NaN   \n",
       "\n",
       "      Date of IPO  IS_SPAC  \n",
       "0       2/29/2016     True  \n",
       "1        3/7/2016     True  \n",
       "2        6/1/2016     True  \n",
       "3        7/7/2016     True  \n",
       "4       9/21/2016     True  \n",
       "...           ...      ...  \n",
       "15297         NaN    False  \n",
       "15298         NaN    False  \n",
       "15299         NaN    False  \n",
       "15300         NaN    False  \n",
       "15301         NaN    False  \n",
       "\n",
       "[15302 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.read_csv('inputs/filtered_data.csv')\n",
    "combined_data.rename(columns={'ticker' : 'tic'}, inplace=True)\n",
    "combined_data.rename(columns={'IPO name' : 'conm'}, inplace=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_ipo_spac_merge = pd.merge(combined_data, ccm_data_filtered, on='tic', how='left')\n",
    "ccm_ipo_spac_merge.to_csv('inputs/ccm_ipo_spac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(query, choices, limit=1):\n",
    "    return process.extract(query, choices, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare a list of choices from the CCM dataset\n",
    "# choices = ccm_data['conm'].unique()\n",
    "\n",
    "# # Apply fuzzy matching to each company name in the SPAC and IPO data\n",
    "# combined_data['matched_name'] = combined_data['conm'].apply(lambda x: get_matches(x, choices)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziggy\\AppData\\Local\\Temp\\ipykernel_28176\\22611733.py:2: DtypeWarning: Columns (29,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ccm_data=pd.read_csv('inputs/all_ccm_data.csv')\n"
     ]
    }
   ],
   "source": [
    "ritter_data = pd.read_csv('inputs/filtered_data.csv')\n",
    "ccm_data=pd.read_csv('inputs/all_ccm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ritter_data['cusip_truncated'] = ritter_data['CUSIP'].str[:6]\n",
    "ccm_data['cusip_truncated'] = ccm_data['cusip'].str[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(ritter_data, ccm_data, on='cusip_truncated', how='left')\n",
    "merged_data.to_csv('inputs/ritter_ccm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  offer date formatted offer date\n",
      "0 1975-01-30           01/30/1975\n",
      "1 1975-06-09           06/09/1975\n",
      "2 1975-06-10           06/10/1975\n",
      "3 1975-07-15           07/15/1975\n",
      "4 1975-08-26           08/26/1975\n",
      "      offer date                     IPO name ticker      CUSIP Rollup VC  \\\n",
      "12940 2017-01-12        Gores Holdings II Inc  GSHTU  382867208      0  0   \n",
      "12941 2017-01-20  Fintech Acquisition Corp II  FNTEU  31810G208      0  0   \n",
      "12942 2017-01-20              Keane Group Inc   FRAC  48669A108      0  0   \n",
      "12943 2017-01-26               AnaptysBio Inc   ANAB  032724106      0  1   \n",
      "12944 2017-01-26                    Obseva SA   OBSV  H5861P103      0  1   \n",
      "\n",
      "      Dual Internet Post-issue shares CRSP perm  Founding  Unnamed: 11  \\\n",
      "12940    1        0          46875000     16631      2016          NaN   \n",
      "12941    1        0          20960000     16630       -99          NaN   \n",
      "12942    0        0                 .     16557      1973          NaN   \n",
      "12943    0        0                 .     16562      2005          NaN   \n",
      "12944    0        0                 .     16573      2012          NaN   \n",
      "\n",
      "      Unnamed: 12 Unnamed: 13 formatted offer date  \n",
      "12940         NaN         NaN           01/12/2017  \n",
      "12941         NaN         NaN           01/20/2017  \n",
      "12942         NaN         NaN           01/20/2017  \n",
      "12943         NaN         NaN           01/26/2017  \n",
      "12944         NaN         NaN           01/26/2017  \n"
     ]
    }
   ],
   "source": [
    "ipo_data['offer date'] = pd.to_datetime(ipo_data['offer date'], format='%Y%m%d')\n",
    "\n",
    "ipo_data['formatted offer date'] = ipo_data['offer date'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "print(ipo_data[['offer date', 'formatted offer date']].head())\n",
    "\n",
    "ipo_data = ipo_data[ipo_data['offer date'].dt.year >= 2017]\n",
    "\n",
    "print(ipo_data.head())\n",
    "\n",
    "ipo_data.to_csv('inputs/cleaned_ipo_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_data.rename(columns={'CUSIP' : 'cusip'}, inplace=True)\n",
    "merged_ccm_ipo = pd.merge(ipo_data, ccm_data, on='cusip', how='left')\n",
    "merged_ccm_ipo.drop_duplicates()\n",
    "merged_ccm_ipo.to_csv('inputs/merged_ccm_ipo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziggy\\AppData\\Local\\Temp\\ipykernel_28176\\3141681762.py:2: DtypeWarning: Columns (29,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('inputs/all_ccm_data.csv')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('inputs/IPO-age(9).csv')\n",
    "df2 = pd.read_csv('inputs/all_ccm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of exact CUSIP matches: 3101\n"
     ]
    }
   ],
   "source": [
    "matches = df1['CUSIP'].isin(df2['cusip'])\n",
    "exact_match_count = matches.sum()\n",
    "print(f\"Number of exact CUSIP matches: {exact_match_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       offer date                        IPO name ticker      CUSIP Rollup VC  \\\n",
      "2089     19860605                         Genzyme   GENZ  372917104      0  1   \n",
      "4619     19920616         Columbia Banking System   COLB  197236102      0  0   \n",
      "4989     19930219     Nuveen Prem Inc Muni Fund 4    NPT  6706K4105      0  0   \n",
      "5106     19930422          TCW/DW Term Trust 2003    TMT  87234U108      0  0   \n",
      "5158     19930520    Nuveen CT Prem Inc Muni Fund    NTC  67060D107      0  0   \n",
      "...           ...                             ...    ...        ...    ... ..   \n",
      "13382    20181214             Legacy Housing Corp   LEGH  52472M101      0  0   \n",
      "13678    20200603         Warner Music Group Corp    WMG  934550203      0  0   \n",
      "14514    20210423                     Agiliti Inc   AGTI  00848J104      1  0   \n",
      "14663    20210701                Krispy Kreme Inc   DNUT  50101L106      0  0   \n",
      "14676    20210713  NorthEast Community Bancorp, I   NECB  664121100      0  0   \n",
      "\n",
      "      Dual Internet Post-issue shares CRSP perm  Founding  Unnamed: 11  \\\n",
      "2089     0        0                 .     10324      1981          NaN   \n",
      "4619     0        0                 .     77679      1988          NaN   \n",
      "4989     0        0                 .     78942       -99          NaN   \n",
      "5106     1        0         100010640     79136       -99          NaN   \n",
      "5158     0        0                 .     79225       -99          NaN   \n",
      "...    ...      ...               ...       ...       ...          ...   \n",
      "13382    0        0                 .     18311      2005          NaN   \n",
      "13678    1        0         510000000     19403      1967          NaN   \n",
      "14514    0        0                 .     20901      1939          NaN   \n",
      "14663    0        0                 .     21594      1937          NaN   \n",
      "14676    0        0                 .     21746      1934          NaN   \n",
      "\n",
      "      Unnamed: 12 Unnamed: 13  \n",
      "2089          NaN         NaN  \n",
      "4619          NaN         NaN  \n",
      "4989          NaN         NaN  \n",
      "5106          NaN         NaN  \n",
      "5158          NaN         NaN  \n",
      "...           ...         ...  \n",
      "13382         NaN         NaN  \n",
      "13678         NaN         NaN  \n",
      "14514         NaN         NaN  \n",
      "14663         NaN         NaN  \n",
      "14676         NaN         NaN  \n",
      "\n",
      "[3101 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "matching_entries =df1[matches]\n",
    "print(matching_entries)\n",
    "matching_entries.to_csv('inputs/matching_entries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPAC IPO</th>\n",
       "      <th>Date of IPO</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>IS_SPAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aetherium Acquisition Corp.</td>\n",
       "      <td>12/29/2021</td>\n",
       "      <td>00809J200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welsbach Technology Metals Acquisition Corp.</td>\n",
       "      <td>12/27/2021</td>\n",
       "      <td>950415208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arogo Capital Acquisition Corp.</td>\n",
       "      <td>12/23/2021</td>\n",
       "      <td>042644203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gardiner Healthcare Acquisitions Corp.</td>\n",
       "      <td>12/21/2021</td>\n",
       "      <td>365506203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Larkspur Health Acquisition Corp.</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>51724W206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>CF Corp.</td>\n",
       "      <td>5/25/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>KLR Energy Acquisition Corp.</td>\n",
       "      <td>3/16/2016</td>\n",
       "      <td>777385204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Jensyn Acquisition Corp.</td>\n",
       "      <td>3/7/2016</td>\n",
       "      <td>47632B201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>Silver Run Acquisition Corp.</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>82811P200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1014 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         SPAC IPO  Date of IPO      CUSIP  \\\n",
       "0                      Aetherium Acquisition Corp.  12/29/2021  00809J200   \n",
       "1     Welsbach Technology Metals Acquisition Corp.  12/27/2021  950415208   \n",
       "2                  Arogo Capital Acquisition Corp.  12/23/2021  042644203   \n",
       "3           Gardiner Healthcare Acquisitions Corp.  12/21/2021  365506203   \n",
       "4                Larkspur Health Acquisition Corp.  12/20/2021  51724W206   \n",
       "...                                            ...         ...        ...   \n",
       "1009                                      CF Corp.   5/25/2016        NaN   \n",
       "1010                  KLR Energy Acquisition Corp.   3/16/2016  777385204   \n",
       "1011                      Jensyn Acquisition Corp.    3/7/2016  47632B201   \n",
       "1012                  Silver Run Acquisition Corp.   2/29/2016  82811P200   \n",
       "1013                                           NaN         NaN        NaN   \n",
       "\n",
       "      IS_SPAC  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "1009        1  \n",
       "1010        1  \n",
       "1011        1  \n",
       "1012        1  \n",
       "1013        1  \n",
       "\n",
       "[1014 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('inputs/matching_entries.csv')\n",
    "df4 = pd.read_csv('inputs/SPACs2016-2021.csv')\n",
    "df4['IS_SPAC'] = 1\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['cusip_trunc'] = df3['CUSIP'].astype(str).str[:4]\n",
    "df4['cusip_trunc'] = df4['CUSIP'].astype(str).str[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partial CUSIP matches: 455\n"
     ]
    }
   ],
   "source": [
    "partial_matches = df3['cusip_trunc'].isin(df4['cusip_trunc'])\n",
    "print(f\"Number of partial CUSIP matches: {partial_matches.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  offer date                       IPO name ticker      CUSIP  \\\n",
      "15          6084    19940616         Liberty Property Trust    LRY  531172104   \n",
      "19          6156    19940728    Home Properties of New York    HME  437306103   \n",
      "29          6344    19941205    Apollo Group (U of Phoenix)  APOLA  037604105   \n",
      "31          6376    19950110                         Diasys   DIYS  252838107   \n",
      "35          6416    19950214  Globalstar Telecommunications  GSTRF  G3930H104   \n",
      "...          ...         ...                            ...    ...        ...   \n",
      "3070       13327    20180926            Sutro Biopharma Inc   STRO  869367102   \n",
      "3083       13352    20181019      Logicbio Therapeutics Inc   LOGC  54142F102   \n",
      "3088       13361    20181031    Axonics Modulation Tech Inc   AXNX  05465P101   \n",
      "3089       13364    20181107         CNFinance Holdings Ltd    CNF  18979T105   \n",
      "3096       13382    20181214            Legacy Housing Corp   LEGH  52472M101   \n",
      "\n",
      "     Rollup  VC Dual Internet Post-issue shares  CRSP perm  Founding  \\\n",
      "15        .   0    1        0          18355548      80691      1972   \n",
      "19        .   0    0        0                 .      80723       -99   \n",
      "29        0   0    1        0          10109239      81138      1981   \n",
      "31        0   0    0        0                 .      81201      1992   \n",
      "35        0   0    0        0                 .      81249      1994   \n",
      "...     ...  ..  ...      ...               ...        ...       ...   \n",
      "3070      0   1    0        0                 .      18128      2003   \n",
      "3083      0   1    0        0                 .      18205      2014   \n",
      "3088      0   1    0        0                 .      18190      2012   \n",
      "3089      0   0    1        0        1360434040      18223      2006   \n",
      "3096      0   0    0        0                 .      18311      2005   \n",
      "\n",
      "      Unnamed: 11  Unnamed: 12  Unnamed: 13 cusip_trunc  IS_SPAC  \n",
      "15            NaN          NaN          NaN        5311        1  \n",
      "19            NaN          NaN          NaN        4373        1  \n",
      "29            NaN          NaN          NaN        0376        1  \n",
      "31            NaN          NaN          NaN        2528        1  \n",
      "35            NaN          NaN          NaN        G393        1  \n",
      "...           ...          ...          ...         ...      ...  \n",
      "3070          NaN          NaN          NaN        8693        1  \n",
      "3083          NaN          NaN          NaN        5414        1  \n",
      "3088          NaN          NaN          NaN        0546        1  \n",
      "3089          NaN          NaN          NaN        1897        1  \n",
      "3096          NaN          NaN          NaN        5247        1  \n",
      "\n",
      "[455 rows x 17 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziggy\\AppData\\Local\\Temp\\ipykernel_28176\\3881764832.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partial_matching['IS_SPAC'] = 1\n"
     ]
    }
   ],
   "source": [
    "partial_matching = df3[partial_matches]\n",
    "partial_matching['IS_SPAC'] = 0\n",
    "print(partial_matching)\n",
    "partial_matching.to_csv('inputs/partial_matching.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziggy\\AppData\\Local\\Temp\\ipykernel_28176\\703254770.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partial_matching.rename(columns={'CUSIP' : 'cusip'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "partial_matching.rename(columns={'CUSIP' : 'cusip'}, inplace=True)\n",
    "\n",
    "partial_matches_merge = pd.merge(partial_matching, ccm_data, on='cusip', how='left')\n",
    "\n",
    "partial_matches_merge.to_csv('inputs/merged_ccm_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "df4 = pd.read_csv('inputs/SPACs2016-2021.csv')\n",
    "df4['Date of IPO'] = pd.to_datetime(df4['Date of IPO'], format='%m/%d/%Y')\n",
    "df4['End'] = df4['Date of IPO'] + pd.DateOffset(years=1)\n",
    "df4['CUSIP'] = df4['CUSIP'].astype(str)\n",
    "df4\n",
    "\n",
    "SPAC_rets = []\n",
    "for index, row in df4.iterrows():\n",
    "    cusip = row['CUSIP']\n",
    "    start = row['Date of IPO']\n",
    "    end   = row['End']\n",
    "    data  = yf.download(cusip, start=start, end=end)\n",
    "    SPAC_rets.append(data)\n",
    "    print(data)\n",
    "    \n",
    "SPAC_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (132,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m non_empty_dfs \u001b[38;5;241m=\u001b[39m [df \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m SPAC_rets \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty]\n\u001b[0;32m      2\u001b[0m non_empty_dfs\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(non_empty_dfs)\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs/test_spac_rets.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ziggy\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m             arrays,\n\u001b[0;32m    861\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    868\u001b[0m             data,\n\u001b[0;32m    869\u001b[0m             index,\n\u001b[0;32m    870\u001b[0m             columns,\n\u001b[0;32m    871\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    872\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    873\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    874\u001b[0m         )\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    877\u001b[0m         {},\n\u001b[0;32m    878\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    882\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ziggy\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:319\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    314\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_2d(values)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(\n\u001b[0;32m    324\u001b[0m         values,\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m         allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ziggy\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:575\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# we could have a 1-dim or 2-dim list here\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# this is equiv of np.asarray, but does object conversion\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# and platform dtype preservation\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# does not convert e.g. [1, \"a\", True] to [\"1\", \"a\", \"True\"] like\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m#  np.asarray would\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(values[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 575\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([convert(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m values[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;66;03m# GH#21861 see test_constructor_list_of_lists\u001b[39;00m\n\u001b[0;32m    578\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([convert(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (132,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "non_empty_dfs = [df for df in SPAC_rets if not df.empty]\n",
    "non_empty_dfs\n",
    "df = pd.DataFrame(non_empty_dfs)\n",
    "df.to_csv('inputs/test_spac_rets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "\n",
    "# ipo_data = pd.read_csv('inputs/IPO-age(9).csv')\n",
    "# tickers = ipo_data['ticker'].dropna().unique()\n",
    "# print(len(tickers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# stock_data = {}\n",
    "# def fetch_ipo_data(tickers):\n",
    "#     # Dictionary to store data\n",
    "#     stock_data = {}\n",
    "\n",
    "#     # Loop over each ticker and fetch data with a progress bar\n",
    "#     for ticker in tqdm(tickers, desc=\"Fetching data\"):\n",
    "#         try:\n",
    "#             stock_info = yf.Ticker(ticker)\n",
    "#             # Fetch historical market data for the last year\n",
    "#             hist_data = stock_info.history(period=\"1y\")\n",
    "#             stock_data[ticker] = hist_data\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to fetch data for {ticker}: {str(e)}\")\n",
    "\n",
    "#     # Combine all DataFrames from the dictionary into a single DataFrame\n",
    "#     combined_data = pd.concat(stock_data, names=['Ticker', 'Date'])\n",
    "    \n",
    "#     # Save the combined data to a CSV file\n",
    "#     combined_data.to_csv('combined_stock_data.csv')\n",
    "#     print(\"Data successfully saved to 'combined_stock_data.csv'.\")\n",
    "# fetch_ipo_data(tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
