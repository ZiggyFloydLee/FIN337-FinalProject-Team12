{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryant\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# !pip install wrds\n",
    "import wrds\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# !pip install fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_data = pd.read_csv('inputs/IPO-age(9).csv')\n",
    "spac_data = pd.read_csv('inputs/SPACs2016-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique CUSIP in IPO dataset: False\n",
      "Unique CUSIP in SPAC dataset: False\n"
     ]
    }
   ],
   "source": [
    "ipo_unique_cusips = ipo_data['CUSIP'].is_unique\n",
    "spac_unique_cusips = spac_data['CUSIP'].is_unique\n",
    "\n",
    "\n",
    "print(\"Unique CUSIP in IPO dataset:\", ipo_unique_cusips)\n",
    "print(\"Unique CUSIP in SPAC dataset:\", spac_unique_cusips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipo_data_clean = ipo_data.drop_duplicates(subset='CUSIP', keep='last')\n",
    "spac_data_clean = spac_data.drop_duplicates(subset='CUSIP', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_clean_data = pd.merge(ipo_data_clean, spac_data_clean, on=['CUSIP'], how='left', suffixes=('_IPO', '_SPAC'))\n",
    "merged_clean_data['IS_SPAC'] = merged_clean_data['SPAC IPO '].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACs Identified:\n",
      "       offer date                        IPO name ticker      CUSIP Rollup VC  \\\n",
      "12695    20160224     Silver Run Acquisition Corp  SRAQU  82811P200      0  0   \n",
      "12696    20160303         Jensyn Acquisition Corp  JSYNU  47632B201      0  0   \n",
      "12724    20160526       Landcadia Holdings II Inc  LCAHU  51476W206      0  0   \n",
      "12736    20160707          M III Acquisition Corp  MIIIU  55378T203      0  0   \n",
      "12758    20160916  Saban Capital Acquisition Corp  SCACU  78516C205      0  0   \n",
      "\n",
      "      Dual Internet Post-issue shares CRSP perm  Founding  Unnamed: 11  \\\n",
      "12695    1        0          45000000     16021       -99          NaN   \n",
      "12696    1        0           5213400     16012      2014          NaN   \n",
      "12724    1        0          30000000     16173      2008          NaN   \n",
      "12736    1        0                -9     16261       -99          NaN   \n",
      "12758    1        0          28500000     16470      2016          NaN   \n",
      "\n",
      "      Unnamed: 12 Unnamed: 13                        SPAC IPO  Date of IPO  \\\n",
      "12695         NaN         NaN     Silver Run Acquisition Corp.   2/29/2016   \n",
      "12696         NaN         NaN         Jensyn Acquisition Corp.    3/7/2016   \n",
      "12724         NaN         NaN         Landcadia Holdings, Inc.    6/1/2016   \n",
      "12736         NaN         NaN          M III Acquisition Corp.    7/7/2016   \n",
      "12758         NaN         NaN  Saban Capital Acquisition Corp.   9/21/2016   \n",
      "\n",
      "       IS_SPAC  \n",
      "12695     True  \n",
      "12696     True  \n",
      "12724     True  \n",
      "12736     True  \n",
      "12758     True  \n",
      "\n",
      "IPOs Not SPACs:\n",
      "   offer date             IPO name ticker     CUSIP Rollup VC Dual Internet  \\\n",
      "0    19750130              ROYSTER    NaN  78088610      .  0    0        0   \n",
      "1    19750609                VARCO    VRC  92212610      .  0    0        0   \n",
      "2    19750610         COORS ADOLPH    TAP  21701610      .  0    1        0   \n",
      "3    19750715  KEYSTONE FOODS CORP    NaN  49348410      .  0    0        0   \n",
      "4    19750826          C. F. BRAUN    NaN  10564710      .  0    0        0   \n",
      "\n",
      "  Post-issue shares CRSP perm  Founding  Unnamed: 11  \\\n",
      "0                 .     67898      1901          NaN   \n",
      "1                 .     63044      1908          NaN   \n",
      "2          35418915     59248      1901          NaN   \n",
      "3                 .     61989      1965          NaN   \n",
      "4                 .     58579      1909          NaN   \n",
      "\n",
      "                                         Unnamed: 12 Unnamed: 13 SPAC IPO   \\\n",
      "0          N=15,447 U.S. IPOs from Jan 1975-Dec 2022         NaN       NaN   \n",
      "1                                                NaN         NaN       NaN   \n",
      "2  Rollup is a 0-1 dummy variable for whether the...         NaN       NaN   \n",
      "3  VC is a dummy with 1 for VC and 2 for a subset...         NaN       NaN   \n",
      "4  Dual is a dummy for multiple share class IPOs ...         NaN       NaN   \n",
      "\n",
      "  Date of IPO  IS_SPAC  \n",
      "0         NaN    False  \n",
      "1         NaN    False  \n",
      "2         NaN    False  \n",
      "3         NaN    False  \n",
      "4         NaN    False  \n"
     ]
    }
   ],
   "source": [
    "spacs_only = merged_clean_data[merged_clean_data['IS_SPAC']]\n",
    "ipos_not_spacs = merged_clean_data[~merged_clean_data['IS_SPAC']]\n",
    "\n",
    "# Display some entries from each dataset\n",
    "print(\"SPACs Identified:\")\n",
    "print(spacs_only.head())\n",
    "\n",
    "print(\"\\nIPOs Not SPACs:\")\n",
    "print(ipos_not_spacs.head())\n",
    "\n",
    "spacs_only.to_csv('inputs/spacs_identified.csv', index=False)\n",
    "ipos_not_spacs.to_csv('inputs/ipos_not_spacs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacs_identified = pd.read_csv('inputs/spacs_identified.csv')\n",
    "ipos_identified = pd.read_csv('inputs/ipos_not_spacs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ipo_spacs = pd.concat([spacs_identified, ipos_not_spacs])\n",
    "combined_ipo_spacs = combined_ipo_spacs.drop_duplicates(subset='CUSIP')\n",
    "combined_ipo_spacs.to_csv('inputs/combined_ipo_spacs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = combined_ipo_spacs[['IPO name', 'ticker', 'CUSIP', 'Date of IPO', 'IS_SPAC']]\n",
    "selected_columns.to_csv('inputs/filtered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_youngfirms = \"inputs/ccm_youngfirms_2000_2018.dta/ccm_youngfirms_2000_2018.dta\"\n",
    "\n",
    "if not os.path.exists(ccm_youngfirms):\n",
    "    zip_path = \"inputs/ccm_youngfirms_2000_2018.zip\"\n",
    "\n",
    "    with zipfile.ZipFile(zip_path,'r') as zip_ref:\n",
    "        zip_ref.extractall(\"inputs/ccm_youngfirms_2000_2018.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_data = pd.read_stata(ccm_youngfirms)\n",
    "ccm_data.to_csv('inputs/all_ccm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_vars = ['tic','adrr', 'curuscn', 'scf', 'src', 'apdedate', 'fdate', 'pdate', 'acominc',\n",
    "                 'acox', 'at', 'am', 'ao', 'aoloch', 'aox', 'ap', 'at', 'caps', 'capx', 'cb',\n",
    "                 'ch', 'che', 'clg', 'cogs', 'csho', 'cusip', 'cshrt', 'cstk', 'dd', 'dlc',\n",
    "                 'dn', 'do', 'datadate', 'dt', 'ebit', 'ebitda', 'epspi', 'fca', 'ffo', 'gdwl',\n",
    "                 'gp', 'ib', 'intan', 'invt', 'lt', 'lct', 'ni', 'niadj', 'np', 'pi', 'ppegt',\n",
    "                 'pnrsho', 'ppent', 're', 'revt', 'sale', 'seq', 'tdc', 'teq', 'tstk', 'txt',\n",
    "                 'wcap', 'naicsh', 'mkvalt', 'acchg', 'accrt', 'amc', 'ano', 'arce', 'cshi',\n",
    "                 'depc', 'derhedgl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_data_filtered =ccm_data[relevant_vars]\n",
    "ccm_data_filtered.to_csv('inputs/ccm_data_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conm</th>\n",
       "      <th>tic</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>Date of IPO</th>\n",
       "      <th>IS_SPAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Silver Run Acquisition Corp</td>\n",
       "      <td>SRAQU</td>\n",
       "      <td>82811P200</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jensyn Acquisition Corp</td>\n",
       "      <td>JSYNU</td>\n",
       "      <td>47632B201</td>\n",
       "      <td>3/7/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Landcadia Holdings II Inc</td>\n",
       "      <td>LCAHU</td>\n",
       "      <td>51476W206</td>\n",
       "      <td>6/1/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M III Acquisition Corp</td>\n",
       "      <td>MIIIU</td>\n",
       "      <td>55378T203</td>\n",
       "      <td>7/7/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Saban Capital Acquisition Corp</td>\n",
       "      <td>SCACU</td>\n",
       "      <td>78516C205</td>\n",
       "      <td>9/21/2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>15297</td>\n",
       "      <td>Aimei Health Technology Co.</td>\n",
       "      <td>AFJKU</td>\n",
       "      <td>G01341117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15298</th>\n",
       "      <td>15298</td>\n",
       "      <td>INNO HOLDINGS INC.</td>\n",
       "      <td>INHD</td>\n",
       "      <td>4576JP109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299</th>\n",
       "      <td>15299</td>\n",
       "      <td>ZKH GROUP LTD</td>\n",
       "      <td>ZKH</td>\n",
       "      <td>98877R104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15300</th>\n",
       "      <td>15300</td>\n",
       "      <td>Linkage Global Inc</td>\n",
       "      <td>LGCB</td>\n",
       "      <td>G5500B102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15301</th>\n",
       "      <td>15301</td>\n",
       "      <td>Iron Horse Acquisition</td>\n",
       "      <td>IROHU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15302 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                            conm    tic      CUSIP  \\\n",
       "0               0     Silver Run Acquisition Corp  SRAQU  82811P200   \n",
       "1               1         Jensyn Acquisition Corp  JSYNU  47632B201   \n",
       "2               2       Landcadia Holdings II Inc  LCAHU  51476W206   \n",
       "3               3          M III Acquisition Corp  MIIIU  55378T203   \n",
       "4               4  Saban Capital Acquisition Corp  SCACU  78516C205   \n",
       "...           ...                             ...    ...        ...   \n",
       "15297       15297     Aimei Health Technology Co.  AFJKU  G01341117   \n",
       "15298       15298              INNO HOLDINGS INC.   INHD  4576JP109   \n",
       "15299       15299                   ZKH GROUP LTD    ZKH  98877R104   \n",
       "15300       15300              Linkage Global Inc   LGCB  G5500B102   \n",
       "15301       15301          Iron Horse Acquisition  IROHU        NaN   \n",
       "\n",
       "      Date of IPO  IS_SPAC  \n",
       "0       2/29/2016     True  \n",
       "1        3/7/2016     True  \n",
       "2        6/1/2016     True  \n",
       "3        7/7/2016     True  \n",
       "4       9/21/2016     True  \n",
       "...           ...      ...  \n",
       "15297         NaN    False  \n",
       "15298         NaN    False  \n",
       "15299         NaN    False  \n",
       "15300         NaN    False  \n",
       "15301         NaN    False  \n",
       "\n",
       "[15302 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.read_csv('inputs/filtered_data.csv')\n",
    "combined_data.rename(columns={'ticker' : 'tic'}, inplace=True)\n",
    "combined_data.rename(columns={'IPO name' : 'conm'}, inplace=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm_ipo_spac_merge = pd.merge(combined_data, ccm_data_filtered, on='tic', how='left')\n",
    "ccm_ipo_spac_merge.to_csv('inputs/ccm_ipo_spac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(query, choices, limit=1):\n",
    "    return process.extract(query, choices, limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare a list of choices from the CCM dataset\n",
    "# choices = ccm_data['conm'].unique()\n",
    "\n",
    "# # Apply fuzzy matching to each company name in the SPAC and IPO data\n",
    "# combined_data['matched_name'] = combined_data['conm'].apply(lambda x: get_matches(x, choices)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_data = {\n",
    "    'cusip_in_ritter':['47632B201'],\n",
    "    'cusip_in_ccm' : ['47632B102']\n",
    "}\n",
    "mapping_table = pd.DataFrame(mapping_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryant\\AppData\\Local\\Temp\\ipykernel_13680\\22611733.py:2: DtypeWarning: Columns (29,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ccm_data=pd.read_csv('inputs/all_ccm_data.csv')\n"
     ]
    }
   ],
   "source": [
    "ritter_data = pd.read_csv('inputs/filtered_data.csv')\n",
    "ccm_data=pd.read_csv('inputs/all_ccm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cusip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13680\\4153325134.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mritter_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cusip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cusip_in_ritter'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_merge_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mccm_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cusip_in_ccm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cusip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ryant\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ryant\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ryant\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1306\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                         \u001b[1;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ryant\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cusip'"
     ]
    }
   ],
   "source": [
    "mapped = pd.merge(ritter_data, mapping_table, left_on='cusip', right_on='cusip_in_ritter', how='left')\n",
    "final_merge_data = pd.merge(mapped, ccm_data, left_on='cusip_in_ccm', right_on='cusip', how='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
